{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\rho$-VAE:\n",
    "\n",
    "This is the basic implementaiton of the $rho$-VAE, a simple fix to the vanilla-VAE, which can be extended to other variants as a plug-and-play addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "%precision  %.3f\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "seed = 1\n",
    "log_interval = 10\n",
    "z_dim = 5\n",
    "#database_name = 'mnist'\n",
    "#database_name = 'cifar10'\n",
    "database_name = 'fashion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "if database_name.lower() == 'mnist':\n",
    "    database_obj_train = datasets.MNIST('data/mnist', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "    database_obj_test = datasets.MNIST('data/mnist', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "elif database_name.lower() == 'cifar10':\n",
    "    database_obj_train = datasets.CIFAR10('data/cifar10', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "    database_obj_test = datasets.CIFAR10('data/cifar10', train=False, transform=transforms.ToTensor())\n",
    "    \n",
    "elif database_name.lower() == 'fashion':\n",
    "    database_obj_train = datasets.FashionMNIST('data/fashion', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "    database_obj_test = datasets.FashionMNIST('data/fashion', train=False, transform=transforms.ToTensor())    \n",
    "    \n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(database_obj_train,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(database_obj_test,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "try:\n",
    "    N_train,image_x,image_y,num_channel = train_loader.dataset.data.shape\n",
    "    data_dim = image_x * image_y * num_channel\n",
    "except:\n",
    "    N_train,image_x,image_y = train_loader.dataset.data.shape\n",
    "    data_dim = image_x * image_y \n",
    "    num_channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rho_VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rho_VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(data_dim, 400)\n",
    "        self.fc21 = nn.Linear(400, z_dim)\n",
    "        self.fc22 = nn.Linear(400, 1)  # rho \n",
    "        self.fc23 = nn.Linear(400, 1)  # s\n",
    "        self.fc3 = nn.Linear(z_dim, 400)\n",
    "        self.fc4 = nn.Linear(400, data_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), torch.tanh(self.fc22(h1)) , self.fc23(h1)    # -1<rho<1,and s>0\n",
    "\n",
    "    def reparameterize(self, mu, rho, logs):\n",
    "\n",
    "        z_q = torch.randn_like(rho).view(-1,1) * torch.sqrt(logs.exp())\n",
    "        for j in range(1,z_dim):\n",
    "            addenum = z_q[:,-1].view(-1,1)  + torch.randn_like(rho).view(-1,1) * torch.sqrt(logs.exp())\n",
    "            z_q = torch.cat(( z_q, addenum ),1)        \n",
    "        z_q  = z_q + mu  \n",
    "        return z_q\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, rho, logs = self.encode(x.view(-1, data_dim))\n",
    "        z = self.reparameterize(mu, rho, logs)\n",
    "        return self.decode(z), mu, rho, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rho_VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, rho, logs):\n",
    "    \n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, data_dim), reduction='sum')\n",
    "    ##\n",
    "    KLD = 0.5 * ( torch.sum(mu.pow(2)) + - z_dim * logs - (z_dim - 1) * torch.log(1 - rho**2) +  z_dim * (logs.exp()-1)  )\n",
    "    KLD = torch.mean(KLD)\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, rho, logs = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, rho, logs)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, rho, logs = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, rho, logs).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(batch_size, num_channel, image_x, image_y)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         './samples/rho_VAE/recon_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 560.089783\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 411.036560\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 357.851440\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 324.763062\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 317.294800\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 304.335602\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 296.171387\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 294.557678\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 289.581635\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 280.326447\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 281.751404\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 274.074921\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 277.426514\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 276.750153\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 271.953461\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 262.674408\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 269.375153\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 278.884003\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 260.364227\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 268.313690\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 253.092026\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 247.597733\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 257.598755\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 254.722244\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 247.127762\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 246.264587\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 268.199615\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 243.916046\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 260.586182\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 255.797058\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 248.933289\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 258.635986\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 254.612000\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 244.682144\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 246.989212\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 248.843445\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 253.653961\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 238.150772\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 240.779160\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 257.643463\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 242.061951\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 252.375549\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 241.988190\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 234.341690\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 255.498291\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 248.953186\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 251.969543\n",
      "====> Epoch: 1 Average loss: 271.9478\n",
      "====> Test set loss: 247.5455\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 240.338867\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 246.304138\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 244.407120\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 248.915390\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 246.949417\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 244.094284\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 246.927887\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 256.003479\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 236.544479\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 246.794067\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 229.584442\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 252.624878\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 245.275223\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 238.529602\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 239.164398\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 223.433609\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 239.501907\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 243.965500\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 236.365509\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 237.245758\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 239.853561\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 244.112610\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 247.334793\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 246.904022\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 236.918839\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 233.888733\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 254.964706\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 234.640671\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 235.689102\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 229.612793\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 243.692276\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 242.414948\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 229.706406\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 248.283157\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 249.725021\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 239.414444\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 246.196487\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 233.196671\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 248.879318\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 246.381729\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 256.781769\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 240.636978\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 244.690933\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 238.354828\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 234.597610\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 240.738220\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 240.932800\n",
      "====> Epoch: 2 Average loss: 242.8204\n",
      "====> Test set loss: 242.2514\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 233.493317\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 245.687515\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 238.161499\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 237.332718\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 260.148712\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 250.421173\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 251.569138\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 251.506516\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 238.346237\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 238.651703\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 239.154388\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 245.837997\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 223.386063\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 254.464859\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 228.926208\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 234.768661\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 244.647110\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 229.912933\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 225.777451\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 247.099426\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 238.950607\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 237.297928\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 228.573715\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 248.832489\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 232.103363\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 248.384338\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 231.336288\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 242.221405\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 243.602921\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 249.467438\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 241.893936\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 236.361130\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 239.775513\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 248.794891\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 242.133194\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 242.599243\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 234.373230\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 241.769119\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 235.169983\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 242.831375\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 241.756912\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 234.866394\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 233.421295\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 245.421204\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 244.284119\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 234.738770\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 224.953323\n",
      "====> Epoch: 3 Average loss: 239.0975\n",
      "====> Test set loss: 240.0524\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 234.195068\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 238.450607\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 231.412033\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 233.508072\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 244.448349\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 224.620560\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 244.198227\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 238.568665\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 232.761734\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 240.709732\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 234.416946\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 234.513428\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 232.923187\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 233.502197\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 239.863998\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 240.136841\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 241.171906\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 233.663589\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 233.961273\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 242.064560\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 245.603622\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 244.504944\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 242.835785\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 232.467834\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 242.599945\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 226.538116\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 249.608093\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 239.475082\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 253.876984\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 249.492233\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 246.809021\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 236.239380\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 245.094452\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 229.786255\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 246.552643\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 226.743668\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 224.999207\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 237.187302\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 240.799606\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 237.134537\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 234.500427\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 238.543381\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 236.313065\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 235.830093\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 231.956512\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 239.861374\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 238.638138\n",
      "====> Epoch: 4 Average loss: 237.1394\n",
      "====> Test set loss: 238.1900\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 235.562454\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 247.149246\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 251.818375\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 239.423538\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 230.781647\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 229.865570\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 234.414902\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 242.836166\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 228.982697\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 229.181946\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 240.127319\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 246.598969\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 240.214767\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 218.845093\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 228.777618\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 231.302841\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 232.973557\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 237.819031\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 232.716614\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 242.030319\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 242.574341\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 238.192719\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 225.166473\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 239.432816\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 234.325089\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 224.744202\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 230.267395\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 226.691055\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 239.246368\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 237.764175\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 231.295425\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 219.908112\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 233.654785\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 234.709122\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 245.681961\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 234.739090\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 234.148727\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 225.666504\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 236.339386\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 230.117096\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 226.588379\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 236.532028\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 238.279800\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 218.432281\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 238.031464\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 234.380997\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 245.560303\n",
      "====> Epoch: 5 Average loss: 235.8490\n",
      "====> Test set loss: 236.9844\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 232.650436\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 223.265121\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 230.472031\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 236.855377\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 225.942688\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 238.951324\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 239.867584\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 239.951218\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 232.129257\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 237.261551\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 232.981369\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 234.284592\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 238.180771\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 243.114563\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 237.865448\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 235.597122\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 239.785706\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 238.494980\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 232.017654\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 237.962189\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 236.217957\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 230.419296\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 240.419327\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 244.482208\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 231.618179\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 239.290497\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 235.312332\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 225.608643\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 240.057999\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 240.429749\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 226.383377\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 233.786865\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 224.013504\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 239.701752\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 232.855515\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 230.864655\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 245.285233\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 243.832108\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 253.597565\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 239.869400\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 229.897720\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 244.054123\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 234.998749\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 235.244171\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 240.157227\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 244.249023\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 232.050613\n",
      "====> Epoch: 6 Average loss: 234.7962\n",
      "====> Test set loss: 236.1442\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 218.121811\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 229.033096\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 223.666992\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 237.897690\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 246.959473\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 233.506668\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 229.214050\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 223.792160\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 240.801865\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 231.748886\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 223.668701\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 240.023849\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 226.793182\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 235.172928\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 232.347366\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 241.464249\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 238.563965\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 228.071350\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 245.121109\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 240.330643\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 225.983368\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 229.301544\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 235.877777\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 231.753143\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 230.776276\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 227.142563\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 227.193848\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 230.155014\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 241.505997\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 235.040817\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 233.135468\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 217.709091\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 244.811310\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 238.736191\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 234.465576\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 236.012390\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 233.790405\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 233.810303\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 240.851807\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 236.899994\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 236.037262\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 238.664230\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 229.646744\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 223.690079\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 224.678345\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 232.764648\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 224.815659\n",
      "====> Epoch: 7 Average loss: 233.9890\n",
      "====> Test set loss: 235.4631\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 234.634293\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 220.969818\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 227.384781\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 232.057877\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 236.136917\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 235.550888\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 239.961441\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 239.949890\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 234.448364\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 231.528214\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 228.900467\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 225.865585\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 238.889130\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 243.732971\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 231.712433\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 231.750717\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 228.833435\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 231.763306\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 234.408600\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 227.940765\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 239.450180\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 228.299500\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 235.779312\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 217.275757\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 234.955566\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 231.016510\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 232.649231\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 227.506012\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 230.499680\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 230.859894\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 230.085632\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 243.071198\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 241.394028\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 233.008331\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 232.902466\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 234.019714\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 238.885757\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 228.988495\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 225.855118\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 232.294815\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 239.268250\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 211.186493\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 221.024719\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 239.201767\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 244.554245\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 253.159805\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 233.465591\n",
      "====> Epoch: 8 Average loss: 233.2922\n",
      "====> Test set loss: 234.8172\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 238.090103\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 229.517670\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 226.282806\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 236.691971\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 232.775345\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 230.147736\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 240.789383\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 230.107086\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 237.693802\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 221.018280\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 235.845535\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 233.416428\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 225.884186\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 234.133942\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 232.956970\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 237.356598\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 229.038773\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 225.989014\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 223.705597\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 230.527084\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 242.876877\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 228.949738\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 238.388931\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 236.624924\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 227.914886\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 224.928253\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 221.632370\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 234.648331\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 227.846603\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 225.357010\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 236.052277\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 232.912308\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 242.482193\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 230.752289\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 233.736206\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 239.442612\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 238.721191\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 237.635437\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 238.295990\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 236.566544\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 244.473053\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 241.384949\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 234.414978\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 230.245392\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 234.549728\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 229.219818\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 226.397812\n",
      "====> Epoch: 9 Average loss: 232.7567\n",
      "====> Test set loss: 234.4815\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 232.222855\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 226.471848\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 239.232910\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 224.120056\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 227.131348\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 230.731583\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 233.075394\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 235.209717\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 227.285370\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 238.560730\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 233.149689\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 216.512131\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 223.427414\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 227.667175\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 235.996948\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 240.542496\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 216.717728\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 227.787064\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 229.072128\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 232.362823\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 229.972031\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 238.291901\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 227.228714\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 230.627228\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 244.665024\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 234.568344\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 226.940247\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 229.002945\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 224.275894\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 227.048874\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 230.677017\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 233.003952\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 237.156296\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 228.795349\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 248.945190\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 247.562668\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 224.692291\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 223.868896\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 229.113663\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 228.676697\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 234.387070\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 239.851669\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 229.535278\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 233.420273\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 243.726929\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 223.074081\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 225.159943\n",
      "====> Epoch: 10 Average loss: 232.2585\n",
      "====> Test set loss: 234.2173\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 234.743469\n",
      "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 225.022690\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 240.126785\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 230.371750\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 236.461594\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 222.446854\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 227.709930\n",
      "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 227.093262\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 225.509109\n",
      "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 231.964020\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 226.276672\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 222.939911\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 224.407257\n",
      "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 222.769180\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 232.197647\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 230.471725\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 236.124908\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 235.067841\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 231.350967\n",
      "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 228.238037\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 226.384293\n",
      "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 242.197006\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 232.625076\n",
      "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 232.475891\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 232.951370\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 230.560425\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 226.353836\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 226.078156\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 234.764191\n",
      "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 229.736862\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 231.682251\n",
      "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 237.807556\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 233.332596\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 225.183334\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 237.263016\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 234.601913\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 227.458328\n",
      "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 229.817490\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 242.723358\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 233.347702\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 225.056747\n",
      "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 227.480103\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 228.911270\n",
      "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 249.882767\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 222.864456\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 235.147110\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 228.880112\n",
      "====> Epoch: 11 Average loss: 231.8331\n",
      "====> Test set loss: 233.5186\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 233.951355\n",
      "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 221.372940\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 226.223938\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 235.761719\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 225.447708\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 229.402069\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 227.531693\n",
      "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 228.141586\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 229.548447\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 227.635574\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 239.810623\n",
      "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 230.388092\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 238.148087\n",
      "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 227.214951\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 233.071594\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 239.718903\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 221.080658\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 226.002823\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 232.195282\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 230.920975\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 242.032608\n",
      "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 224.034775\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 233.234055\n",
      "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 229.642654\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 223.729080\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 237.147552\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 222.292221\n",
      "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 229.221375\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 236.879913\n",
      "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 228.241348\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 229.108551\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 240.557358\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 232.607544\n",
      "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 238.532944\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 226.803497\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 240.787704\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 243.199493\n",
      "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 221.967377\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 232.326157\n",
      "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 234.901871\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 220.821442\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 237.979218\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 231.612228\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 214.812195\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 234.296616\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 220.386154\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 228.610077\n",
      "====> Epoch: 12 Average loss: 231.4793\n",
      "====> Test set loss: 233.1853\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 228.130966\n",
      "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 243.141357\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 221.907379\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 226.899384\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 226.397995\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 231.309570\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 236.942688\n",
      "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 234.603836\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 232.961227\n",
      "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 232.070175\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 236.312332\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 228.262512\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 232.946442\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 234.427353\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 234.795044\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 223.141174\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 232.131653\n",
      "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 232.864578\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 222.855347\n",
      "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 216.593109\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 222.537872\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 243.351822\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 219.761520\n",
      "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 231.496826\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 237.992264\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 218.685410\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 232.257843\n",
      "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 227.530243\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 240.231476\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 245.949570\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 234.239426\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 226.922363\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 233.190918\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 232.391983\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 250.054138\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 231.926285\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 227.595123\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 229.750427\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 232.817886\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 242.061295\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 227.375702\n",
      "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 234.756958\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 218.836487\n",
      "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 240.500809\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 242.375473\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 222.855316\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 239.070679\n",
      "====> Epoch: 13 Average loss: 231.1607\n",
      "====> Test set loss: 233.0564\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 223.356628\n",
      "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 230.178314\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 228.655273\n",
      "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 228.906067\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 239.658249\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 220.109451\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 240.761230\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 239.670898\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 228.760132\n",
      "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 228.718323\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 236.668625\n",
      "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 225.262863\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 226.751923\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 229.419678\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 231.090927\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 235.984634\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 225.529739\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 227.575562\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 225.846634\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 225.246902\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 214.395798\n",
      "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 220.490921\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 230.642014\n",
      "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 239.104630\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 229.097885\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 227.713669\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 229.836334\n",
      "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 236.423325\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 228.939987\n",
      "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 228.478058\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 234.509705\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 220.166092\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 232.253647\n",
      "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 233.294876\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 226.643188\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 227.574921\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 240.882339\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 231.544220\n",
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 228.730576\n",
      "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 232.005600\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 235.070541\n",
      "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 234.410492\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 230.435822\n",
      "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 232.918533\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 229.188995\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 232.343506\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 226.133301\n",
      "====> Epoch: 14 Average loss: 230.8742\n",
      "====> Test set loss: 232.7441\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 220.531601\n",
      "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 235.827484\n",
      "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 225.380539\n",
      "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 230.185532\n",
      "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 241.712234\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 229.867645\n",
      "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 233.721558\n",
      "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 237.668869\n",
      "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 220.248657\n",
      "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 232.492889\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 218.442993\n",
      "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 228.144775\n",
      "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 223.713928\n",
      "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 237.215500\n",
      "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 231.320709\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 223.349411\n",
      "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 226.520798\n",
      "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 218.721054\n",
      "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 232.330902\n",
      "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 228.462296\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 234.978088\n",
      "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 224.269363\n",
      "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 237.302307\n",
      "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 226.368103\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 239.300552\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 225.796356\n",
      "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 237.015289\n",
      "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 220.704315\n",
      "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 222.091064\n",
      "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 230.762131\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 232.519714\n",
      "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 226.315552\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 229.532181\n",
      "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 242.613739\n",
      "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 231.326782\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 224.767776\n",
      "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 216.214386\n",
      "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 233.426697\n",
      "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 230.629395\n",
      "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 233.779572\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 229.154312\n",
      "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 226.241623\n",
      "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 228.037903\n",
      "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 242.773483\n",
      "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 237.738434\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 225.699890\n",
      "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 230.052200\n",
      "====> Epoch: 15 Average loss: 230.6191\n",
      "====> Test set loss: 232.6274\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, z_dim).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(64, num_channel, image_x, image_y),'./samples/rho_VAE/sample_' + str(epoch) + '.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cv_env]",
   "language": "python",
   "name": "conda-env-pytorch_cv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
