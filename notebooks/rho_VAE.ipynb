{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\rho$-VAE:\n",
    "\n",
    "This is the basic implementaiton of the $rho$-VAE, a simple fix to the vanilla-VAE, which can be extended to other variants as a plug-and-play addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "%precision  %.3f\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "seed = 1\n",
    "log_interval = 10\n",
    "z_dim = 5\n",
    "#database_name = 'mnist'\n",
    "#database_name = 'cifar10'\n",
    "database_name = 'fashion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "if database_name.lower() == 'mnist':\n",
    "    database_obj_train = datasets.MNIST('data/mnist', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "    database_obj_test = datasets.MNIST('data/mnist', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "elif database_name.lower() == 'cifar10':\n",
    "    database_obj_train = datasets.CIFAR10('data/cifar10', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "    database_obj_test = datasets.CIFAR10('data/cifar10', train=False, transform=transforms.ToTensor())\n",
    "    \n",
    "elif database_name.lower() == 'fashion':\n",
    "    database_obj_train = datasets.FashionMNIST('data/fashion', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "    database_obj_test = datasets.FashionMNIST('data/fashion', train=False, transform=transforms.ToTensor())    \n",
    "    \n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(database_obj_train,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(database_obj_test,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "try:\n",
    "    N_train,image_x,image_y,num_channel = train_loader.dataset.data.shape\n",
    "    data_dim = image_x * image_y * num_channel\n",
    "except:\n",
    "    N_train,image_x,image_y = train_loader.dataset.data.shape\n",
    "    data_dim = image_x * image_y \n",
    "    num_channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rho_VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rho_VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(data_dim, 400)\n",
    "        self.fc21 = nn.Linear(400, z_dim)\n",
    "        self.fc22 = nn.Linear(400, 1)  # rho \n",
    "        self.fc23 = nn.Linear(400, 1)  # s\n",
    "        self.fc3 = nn.Linear(z_dim, 400)\n",
    "        self.fc4 = nn.Linear(400, data_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), torch.tanh(self.fc22(h1)) , self.fc23(h1)    # -1<rho<1,and s>0\n",
    "\n",
    "    def reparameterize(self, mu, rho, logs):\n",
    "        z_q = torch.randn_like(rho).view(-1,1) * torch.sqrt(logs.exp())\n",
    "        for j in range(1,z_dim):\n",
    "            addenum = rho * z_q[:,-1].view(-1,1)  + torch.randn_like(rho).view(-1,1) * torch.sqrt(logs.exp())\n",
    "            z_q = torch.cat(( z_q, addenum ),1)        \n",
    "        z_q  = z_q + mu  \n",
    "        \n",
    "        return z_q\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, rho, logs = self.encode(x.view(-1, data_dim))\n",
    "        z = self.reparameterize(mu, rho, logs)\n",
    "        return self.decode(z), mu, rho, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rho_VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, rho, logs):\n",
    "    \n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, data_dim), reduction='sum')\n",
    "    ##\n",
    "    KLD = 0.5 * ( torch.sum(mu.pow(2)) + - z_dim * logs - (z_dim - 1) * torch.log(1 - rho**2 + 1e-7) +  z_dim * (logs.exp()-1)  )\n",
    "    KLD = torch.mean(KLD)\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, rho, logs = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, rho, logs)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, rho, logs = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, rho, logs).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(batch_size, num_channel, image_x, image_y)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         './samples/rho_VAE/recon_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 549.610046\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 409.925964\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 345.217987\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 319.488434\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 314.691833\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 301.684265\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 293.448212\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 292.996185\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 286.971069\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 275.463501\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 279.188049\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 268.476776\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 274.687744\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 273.402252\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 271.596375\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 261.836304\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 268.930542\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 278.603058\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 260.332092\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 266.745575\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 252.244812\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 246.748566\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 257.426147\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 253.848938\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 246.955841\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 246.327942\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 268.128021\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 243.277252\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 260.286926\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 255.853394\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 247.688522\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 257.161194\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 253.129013\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 243.987030\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 246.652542\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 247.992935\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 253.121048\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 237.819473\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 237.997498\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 256.469055\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 240.159225\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 251.286301\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 241.295914\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 232.920700\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 254.951340\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 247.325012\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 251.069977\n",
      "====> Epoch: 1 Average loss: 270.1887\n",
      "====> Test set loss: 246.8322\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 239.579315\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 245.835831\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 243.137772\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 247.449677\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 245.995560\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 242.308884\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 246.652588\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 255.044586\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 235.190903\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 245.521942\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 228.027206\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 251.573776\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 244.617142\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 237.833496\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 239.620972\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 222.790100\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 239.032440\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 242.641373\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 234.981003\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 236.629761\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 239.245605\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 243.331329\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 246.737076\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 246.632248\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 235.820633\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 233.439972\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 254.389038\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 234.011627\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 235.493149\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 228.654251\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 242.494980\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 241.649643\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 228.888321\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 248.847183\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 249.285217\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 238.428711\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 245.517792\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 232.479446\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 248.629364\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 246.130096\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 256.354980\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 241.085175\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 244.618576\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 236.087723\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 234.316086\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 240.381592\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 240.375183\n",
      "====> Epoch: 2 Average loss: 242.2209\n",
      "====> Test set loss: 241.8936\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 233.158081\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 245.152115\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 237.610382\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 236.851440\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 259.741821\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 250.790756\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 251.308456\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 251.725128\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 239.434860\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 237.898926\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 240.025635\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 245.281296\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 223.719498\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 254.007935\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 229.733704\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 233.755737\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 244.510574\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 229.909119\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 226.238632\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 246.843689\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 238.474716\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 237.837555\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 228.495987\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 248.968201\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 231.787048\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 247.755966\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 231.811874\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 242.105759\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 243.932037\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 249.985016\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 241.830139\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 236.414703\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 238.917130\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 247.938797\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 241.332916\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 241.893372\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 233.609375\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 240.890884\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 235.792023\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 242.958054\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 241.833939\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 234.348236\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 232.533737\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 244.462585\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 243.902222\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 234.944534\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 224.261871\n",
      "====> Epoch: 3 Average loss: 239.0155\n",
      "====> Test set loss: 239.6279\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 235.074265\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 238.397690\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 231.274841\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 231.628479\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 244.656082\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 224.902740\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 243.003601\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 239.029144\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 232.089371\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 239.911148\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 234.505630\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 234.757767\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 233.545120\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 233.825073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 239.727310\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 240.244293\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 240.595871\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 233.315292\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 234.494629\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 242.382874\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 245.045944\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 244.851013\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 242.623627\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 231.276825\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 242.834763\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 226.242645\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 248.802475\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 239.578781\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 253.563187\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 249.336090\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 246.643539\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 236.421127\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 245.012939\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 229.837997\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 246.742676\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 227.363785\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 224.612366\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 235.514801\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 240.420410\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 236.621155\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 234.808029\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 237.425751\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 236.317810\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 235.192062\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 232.285675\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 239.305359\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 238.337173\n",
      "====> Epoch: 4 Average loss: 237.0256\n",
      "====> Test set loss: 238.0768\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 235.439148\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 247.060181\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 251.376450\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 238.835861\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 229.977554\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 229.092575\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 234.133530\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 242.393555\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 228.827438\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 229.332184\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 239.888550\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 246.916946\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 239.423660\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 219.060791\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 228.269897\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 231.154678\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 232.381546\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 237.203705\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 232.800339\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 241.911484\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 242.227448\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 237.816971\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 224.771622\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 238.919617\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 233.741074\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 225.047821\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 230.477966\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 227.038513\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 239.064117\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 237.486313\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 231.559113\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 219.347626\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 233.312088\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 234.308548\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 245.160873\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 235.195877\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 233.724289\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 225.692245\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 235.764450\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 230.566254\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 226.224396\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 235.837494\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 237.801727\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 218.157303\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 237.344269\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 233.907776\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 245.284470\n",
      "====> Epoch: 5 Average loss: 235.5914\n",
      "====> Test set loss: 236.7736\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 231.981552\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 222.885742\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 230.223068\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 236.278091\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 226.345596\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 238.375473\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 239.929123\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 239.414276\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 232.239655\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 237.574249\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 232.950699\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 234.156586\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 237.848236\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 242.732590\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 237.652557\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 234.378464\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 239.153610\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 238.219864\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 232.236450\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 238.263962\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 235.353378\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 230.012405\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 240.117935\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 244.561707\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 231.416168\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 239.143677\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 234.593246\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 225.380203\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 239.606201\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 240.431686\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 225.918488\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 232.815460\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 223.735016\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 238.921799\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 232.649078\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 230.435684\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 244.280457\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 243.818314\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 252.793518\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 239.758575\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 229.744400\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 242.751465\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 234.552063\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 234.649582\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 239.762054\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 244.294678\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 231.753296\n",
      "====> Epoch: 6 Average loss: 234.5302\n",
      "====> Test set loss: 236.1088\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 217.478806\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 228.433640\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 222.601791\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 237.713852\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 247.252838\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 233.438751\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 228.459000\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 224.173264\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 240.917175\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 231.130569\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 223.931702\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 239.840088\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 226.569702\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 234.715851\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 231.874588\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 240.613739\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 238.101852\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 227.951385\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 244.609222\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 240.416275\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 225.052429\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 229.328613\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 236.283722\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 231.332092\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 230.047806\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 227.188919\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 226.979889\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 230.082489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 241.365250\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 234.996414\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 231.764648\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 216.605347\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 244.121246\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 237.955612\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 234.087540\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 235.375290\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 233.774811\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 233.294174\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 240.086594\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 236.476898\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 236.249542\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 238.324158\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 228.666199\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 223.979614\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 224.463715\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 232.417053\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 223.857697\n",
      "====> Epoch: 7 Average loss: 233.7705\n",
      "====> Test set loss: 235.1554\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 234.080307\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 221.087921\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 227.061661\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 231.749786\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 236.134033\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 235.507614\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 238.592804\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 238.630142\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 233.681931\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 231.102768\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 229.148621\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 225.286377\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 239.200974\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 243.290695\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 230.963013\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 231.807526\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 228.784805\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 232.009811\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 234.125320\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 227.638977\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 238.654251\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 227.947311\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 235.033646\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 216.766296\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 234.766266\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 231.002777\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 233.091263\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 226.546478\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 230.328354\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 230.699234\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 229.519714\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 243.038696\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 241.518280\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 233.605927\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 233.423050\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 233.809433\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 238.049683\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 229.288574\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 225.497681\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 232.245636\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 239.790634\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 210.117172\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 221.505280\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 239.038330\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 244.172287\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 252.527664\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 233.760605\n",
      "====> Epoch: 8 Average loss: 233.0126\n",
      "====> Test set loss: 234.7252\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 238.386871\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 229.536560\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 226.307892\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 235.689667\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 232.019104\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 229.688492\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 240.405212\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 229.410553\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 237.514801\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 221.097534\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 235.651855\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 233.679794\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 225.331940\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 233.978806\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 232.520538\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 236.461365\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 229.290176\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 225.348160\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 223.609161\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 230.360596\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 243.109116\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 229.001022\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 238.061844\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 236.661819\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 228.034943\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 224.262680\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 222.240707\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 234.118896\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 227.480667\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 225.563980\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 235.277573\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 232.633987\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 242.136368\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 231.257126\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 233.499481\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 238.963898\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 238.433517\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 237.297607\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 238.419724\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 235.394714\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 244.522873\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 241.020157\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 234.285797\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 231.142349\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 234.171570\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 228.493469\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 226.107666\n",
      "====> Epoch: 9 Average loss: 232.5520\n",
      "====> Test set loss: 234.1055\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 231.224289\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 225.405380\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 238.574570\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 223.182388\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 226.988510\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 230.678177\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 232.971481\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 234.531158\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 226.927750\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 237.804276\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 232.319321\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 216.320663\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 223.171570\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 226.734726\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 236.474655\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 240.101425\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 216.697433\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 227.900528\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 228.626328\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 232.167709\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 230.718887\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 238.143051\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 226.730682\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 231.886703\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 245.729294\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 234.243118\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 228.017639\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 228.255478\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 223.953186\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 226.296967\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 230.832901\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 233.014145\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 237.402695\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 228.686569\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 249.119476\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 248.237473\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 224.509460\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 224.273438\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 229.097198\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 228.589081\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 234.773422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 239.544601\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 228.607544\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 233.496353\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 243.450562\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 222.740265\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 224.990341\n",
      "====> Epoch: 10 Average loss: 232.0629\n",
      "====> Test set loss: 233.9971\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 234.344986\n",
      "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 225.215424\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 240.003220\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 229.920502\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 236.543503\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 222.134094\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 227.244324\n",
      "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 227.170639\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 225.409622\n",
      "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 231.928635\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 226.657761\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 222.735687\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 223.626877\n",
      "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 222.713181\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 232.208817\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 230.383316\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 234.938766\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 235.090714\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 231.062241\n",
      "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 228.459518\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 226.530655\n",
      "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 242.974869\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 232.797256\n",
      "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 232.328018\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 232.344971\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 230.487396\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 226.732254\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 226.046906\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 234.416977\n",
      "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 229.828568\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 231.999405\n",
      "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 237.501343\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 233.056564\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 225.190002\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 237.425461\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 234.669235\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 227.145691\n",
      "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 229.389069\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 243.486954\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 232.900879\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 224.912704\n",
      "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 226.959396\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 228.928574\n",
      "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 250.371979\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 222.249603\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 234.838638\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 228.828690\n",
      "====> Epoch: 11 Average loss: 231.6173\n",
      "====> Test set loss: 233.4203\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 233.893967\n",
      "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 221.312805\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 225.956863\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 235.427795\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 225.888336\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 229.020981\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 227.337143\n",
      "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 228.327393\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 228.665405\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 226.870300\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 239.098724\n",
      "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 230.780334\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 237.471375\n",
      "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 226.876663\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 233.586365\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 239.223740\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 220.353683\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 224.890793\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 231.465408\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 231.031662\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 241.563553\n",
      "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 224.316742\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 232.943192\n",
      "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 229.155930\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 223.644806\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 237.389297\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 222.269165\n",
      "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 229.155670\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 236.378311\n",
      "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 227.914673\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 228.941940\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 240.264496\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 232.879089\n",
      "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 238.633728\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 227.047104\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 240.437317\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 242.841949\n",
      "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 222.037476\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 232.194473\n",
      "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 234.877625\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 220.672745\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 237.748520\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 232.414932\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 214.752914\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 233.451004\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 220.172470\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 229.621643\n",
      "====> Epoch: 12 Average loss: 231.2787\n",
      "====> Test set loss: 233.3029\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 228.321518\n",
      "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 242.834641\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 221.815521\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 226.490829\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 226.514313\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 231.195572\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 236.825241\n",
      "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 234.563309\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 233.022293\n",
      "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 232.110611\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 235.395538\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 228.161224\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 232.431183\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 234.370087\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 235.407928\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 222.949341\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 231.345139\n",
      "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 232.747711\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 222.467743\n",
      "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 215.862549\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 222.190430\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 242.523102\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 219.121017\n",
      "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 231.111389\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 237.839920\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 219.221970\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 232.102814\n",
      "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 226.580429\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 240.336243\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 246.089172\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 233.755219\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 227.248154\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 233.511307\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 232.103912\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 249.730942\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 231.061172\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 227.834457\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 229.933167\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 233.188904\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 242.964355\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 226.357193\n",
      "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 234.102356\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 219.064606\n",
      "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 240.688843\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 241.980789\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 222.499893\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 238.876877\n",
      "====> Epoch: 13 Average loss: 230.9473\n",
      "====> Test set loss: 232.8780\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 223.588928\n",
      "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 229.930862\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 228.348877\n",
      "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 228.536377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 239.930725\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 219.601746\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 240.580444\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 238.970703\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 229.269058\n",
      "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 229.061172\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 237.237427\n",
      "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 224.794098\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 226.153168\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 229.795914\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 231.021896\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 236.554733\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 225.471710\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 227.749756\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 225.867462\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 225.082657\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 214.534607\n",
      "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 219.408035\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 231.249115\n",
      "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 239.288239\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 228.922211\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 227.553238\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 229.834900\n",
      "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 235.888260\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 228.929749\n",
      "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 227.839630\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 234.440353\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 220.019241\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 231.278015\n",
      "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 232.544785\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 226.422867\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 227.586624\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 240.254639\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 232.227890\n",
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 228.199677\n",
      "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 231.304138\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 235.157288\n",
      "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 234.044632\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 229.700806\n",
      "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 232.303528\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 228.930969\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 232.377167\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 225.094498\n",
      "====> Epoch: 14 Average loss: 230.6596\n",
      "====> Test set loss: 232.6384\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 219.850418\n",
      "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 235.319199\n",
      "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 226.217850\n",
      "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 230.027786\n",
      "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 241.817978\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 231.441696\n",
      "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 233.300964\n",
      "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 237.589020\n",
      "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 219.984497\n",
      "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 232.738007\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 218.133011\n",
      "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 227.554855\n",
      "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 223.394302\n",
      "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 238.660934\n",
      "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 230.502502\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 223.453262\n",
      "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 225.684418\n",
      "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 218.444122\n",
      "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 232.065964\n",
      "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 228.387131\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 234.523117\n",
      "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 224.962738\n",
      "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 237.142715\n",
      "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 226.541840\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 238.615677\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 225.063080\n",
      "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 236.070862\n",
      "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 221.111359\n",
      "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 221.867386\n",
      "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 230.282379\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 231.837830\n",
      "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 225.304001\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 229.069031\n",
      "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 241.733765\n",
      "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 230.659134\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 224.881866\n",
      "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 215.820618\n",
      "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 233.194321\n",
      "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 230.582520\n",
      "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 232.981857\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 229.059082\n",
      "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 226.149719\n",
      "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 227.333145\n",
      "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 242.309784\n",
      "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 237.655472\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 224.311386\n",
      "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 229.522552\n",
      "====> Epoch: 15 Average loss: 230.4446\n",
      "====> Test set loss: 232.3324\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, z_dim).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(64, num_channel, image_x, image_y),'./samples/rho_VAE/sample_' + str(epoch) + '.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cv_env]",
   "language": "python",
   "name": "conda-env-pytorch_cv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
